---
layout:     post                    # 使用的布局（不需要改）
title:      使用谷歌API训练自己检测器              # 标题 
subtitle:   仰望星空，脚踏实地         #副标题
date:       2019-07-3              # 时间
author:     BY Seaside                     # 作者
header-img: img/memory/9.jpeg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - tool 
    - DL
---

# 使用谷歌API训练自己检测器

# 0. 快速开始

Setup:

- [Installation](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md)

Quick Start:

- [Quick Start: Jupyter notebook for off-the-shelf inference](https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb)
- [Quick Start: Training a pet detector](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_pets.md)

推荐文件夹格式：

annotations — 标注xml文件

data — 转化后tf record文件

images — 原数据集

training  — 训练模型以及配置文件

# 1. 制作图像数据集

## 数据来源

 [Google Images](https://images.google.com/) and [Pixabay](https://pixabay.com/) 

- jpeg or png

- bounding boxes (`xmin, ymin, xmax, ymax`) 

## 数据标注工具

几种格式：PASCAL VOC format， COCO

- [LabelImg](https://github.com/tzutalin/labelImg)

> saved as XML files in the PASCAL VOC format 

[XML 转换 CSV格式](https://gist.github.com/seaside2mm/5b3ee02404f46601f43ff012f679d7bb)

-  [FIAT (Fast Image Data Annotation Tool)](https://github.com/christopher5106/FastAnnotationTool)

## csv数据集划分

[划分训练和测试](https://gist.github.com/seaside2mm/8cd6c846936a441489bc310d69b1d42a)

## TFRecord数据格式

生成方法：

 [PASCAL VOC dataset](http://host.robots.ox.ac.uk/pascal/VOC/) 

[create_pascal_tf_record.py](<https://github.com/tensorflow/models/blob/master/research/object_detection/dataset_tools/create_pascal_tf_record.py>)

图像格式转换

 [ImageMagick](http://imagemagick.org/#)

# 2. 训练模型

利用 [TensorFlow’s new Object Detector API](https://research.googleblog.com/2017/06/supercharge-your-computer-vision-models.html)进行模型训练。

## 更改配置文件

- 选择具体NN模型更改 [config files](https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs)

 [object detection training pipeline](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/configuring_jobs.md). 

```
tf_record_input_reader {
  input_path: "/usr/home/username/data/train.record"
}
label_map_path: "/usr/home/username/data/label_map.pbtxt"
```

- label map

 [选择相对应label map](https://github.com/tensorflow/models/tree/master/research/object_detection/data). 比如，只有一个label时：

```
item {
  id: 1
  name: 'person'
}
```

## Pre-trained model checkpoint

选择已经训练好的模型进行模型迁移，减少计算量。可选择项。 [several model checkpoint](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md) 

## 训练

- Training can be either done [locally](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_locally.md) or on the [cloud](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_cloud.md) (AWS, Google Cloud etc.). If you have GPU (at least more than 2 GB) at home then you can do it locally otherwise I would recommend to go with the cloud. In my case, I went with [Google Cloud](http://cloud.google.com/) this time and essentially followed all the steps described in [their documentation](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_cloud.md).
- For Google Cloud, you need to define a YAML configuration file. A [sample file is also provided](https://github.com/tensorflow/models/blob/master/research/object_detection/samples/cloud/cloud.yml) and I basically just took the default values.
- It is also recommended during the training to start the evaluation job. You can then monitor the process of the training and evaluation jobs by running [Tensorboard](https://www.tensorflow.org/get_started/summaries_and_tensorboard) on your local machine.

# 3. 导出模型

copy the model checkpoints from the Google Cloud bucket to my local machine and then used the [provided script](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/exporting_models.md) to export the model.

After export, you should see the directory ${EXPORT_DIR} containing the following:

- saved_model/, a directory containing the saved model format of the exported model
- frozen_inference_graph.pb, the frozen graph format of the exported model
- model.ckpt.*, the model checkpoints used for exporting
- checkpoint, a file specifying to restore included checkpoint files
- pipeline.config, pipeline config file for the exported model



# 参考

https://github.com/tensorflow/models/tree/master/research/object_detection

https://towardsdatascience.com/how-to-train-your-own-object-detector-with-tensorflows-object-detector-api-bec72ecfe1d9

