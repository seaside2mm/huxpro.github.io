---
layout:     post                    # 使用的布局（不需要改）
title:     bolt源码梳理(中)--核心流程实现               # 标题 
subtitle:   走多了便成了路 #副标题
date:       2018-08-24              # 时间
author:     BY  Seaside                    # 作者
#header-img: img/post-bg-2015.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - boltdb 
    - database

---





# boltdb 启动和初始化

根据前面的简述，`boltdb`只使用单个文件进行持久化，在`boltdb`启动时，会先打开对应的 持久化文件，然后根据是否是只读模式来获取该文件的文件锁。

当不是只读模式时，`boltdb` 会采用排他文件锁来保证只有一个进程能够操作该文件，避免多个进程同时操作，造成数据毁坏。

当持久化文件大小为0时，`boltdb`会认为该数据库为新创建的，然后对其进行初始化(写入4个初 始page)，然后将文件映射到内存空间，最后从映射的内存中读取`meta0`、`meta1`数据。

然后从从meta数据中标识的当前freelist页来读取freelist pgid数据，然后freelist根据这些 数据构建free page cache。即用一个map来记录那些page是空闲的。

此时即完成启动和初始化。

```go
// Open creates and opens a database at the given path.
// If the file does not exist then it will be created automatically.
// Passing in nil options will cause Bolt to open the database with the default options.
func Open(path string, mode os.FileMode, options *Options) (*DB, error) {
    //创建DB对象，并将其状态设为opened；
	var db = &DB{opened: true}

	// Set default options if no options are provided.
	if options == nil {
		options = DefaultOptions
	}
	db.NoGrowSync = options.NoGrowSync
	db.MmapFlags = options.MmapFlags

	// Set default values for later DB operations.
	db.MaxBatchSize = DefaultMaxBatchSize
	db.MaxBatchDelay = DefaultMaxBatchDelay
	db.AllocSize = DefaultAllocSize

    //打开或创建文件对象
    //根据Open参数ReadOnly决定是否以进程独占的方式打开文件，如果以只读方式访问数据库文件，则不同进程可以共享读该文件；如果以读写方式访问数据库文件，则文件锁将被独占，其他进程无法同时以读写方式访问该数据库文件，这是为了防止多个进程同时修改文件；

	flag := os.O_RDWR
	if options.ReadOnly {
		flag = os.O_RDONLY
		db.readOnly = true
	}

	// Open data file and separate sync handler for metadata writes.
	db.path = path
	var err error
    //第一步，打开数据文件
	if db.file, err = os.OpenFile(db.path, flag|os.O_CREATE, mode); err != nil {
		_ = db.close()
		return nil, err
	}

	// Lock file so that other processes using Bolt in read-write mode cannot
	// use the database  at the same time. This would cause corruption since
	// the two processes would write meta pages and free pages separately.
	// The database file is locked exclusively (only one process can grab the lock)
	// if !options.ReadOnly.
	// The database file is locked using the shared lock (more than one process may
	// hold a lock at the same time) otherwise (options.ReadOnly is set).
    
    //第二步，文件锁，防止多个操作数据库文件
	if err := flock(db, mode, !db.readOnly, options.Timeout); err != nil {
		_ = db.close()
		return nil, err
	}

	// Default values for test hooks
	db.ops.writeAt = db.file.WriteAt

    //读数据库文件，如果文件大小为零，则对db进行初始化；如果大小不为零，则试图读取前4K个字节来确定当前数据库的pageSize。随后我们分析db的初始化时，会看到db的文件格式，可以进一步理解这里的逻辑；
	if info, err := db.file.Stat(); err != nil {
		return nil, err
	} else if info.Size() == 0 {     
		// Initialize new files with meta pages.初始化(写入4个初始page)，db.init()
		if err := db.init(); err != nil {
			return nil, err
		}
	} else {
		// Read the first meta page to determine the page size.
		var buf [0x1000]byte
		if _, err := db.file.ReadAt(buf[:], 0); err == nil {
			m := db.pageInBuffer(buf[:], 0).meta()
			if err := m.validate(); err != nil {
				// If we can't read the page size, we can assume it's the same
				// as the OS -- since that's how the page size was chosen in the
				// first place.
				//
				// If the first page is invalid and this OS uses a different
				// page size than what the database was created with then we
				// are out of luck and cannot access the database.
				db.pageSize = os.Getpagesize()
			} else {
				db.pageSize = int(m.pageSize)
			}
		}
	}

	// Initialize page pool.
	db.pagePool = sync.Pool{
		New: func() interface{} {
			return make([]byte, db.pageSize)
		},
	}

    //通过mmap对打开的数据库文件进行内存映射，并初始化db对象中的meta指针；
	// Memory map the data file.
	if err := db.mmap(options.InitialMmapSize); err != nil {
		_ = db.close()
		return nil, err
	}

    //读数据库文件中的freelist页，并初始化db对象中的freelist列表。freelist列表中记录着数据库文件中的空闲页。
	db.freelist = newFreelist()
	db.freelist.read(db.page(db.meta().freelist))

	// Mark the database as opened and return.
	return db, nil
}

```



```go
// init creates a new database file and initializes its meta pages.
func (db *DB) init() error {
	// Set the page size to the OS page size.
	db.pageSize = os.Getpagesize()

	// Create two meta pages on a buffer.
	buf := make([]byte, db.pageSize*4)
	for i := 0; i < 2; i++ {
		p := db.pageInBuffer(buf[:], pgid(i))
		p.id = pgid(i)
		p.flags = metaPageFlag

		// Initialize the meta page.
		m := p.meta()
		m.magic = magic
		m.version = version
		m.pageSize = uint32(db.pageSize)
		m.freelist = 2
		m.root = bucket{root: 3}
		m.pgid = 4
		m.txid = txid(i)
		m.checksum = m.sum64()
	}

	// Write an empty freelist at page 3.
	p := db.pageInBuffer(buf[:], pgid(2))
	p.id = pgid(2)
	p.flags = freelistPageFlag
	p.count = 0

	// Write an empty leaf page at page 4.
	p = db.pageInBuffer(buf[:], pgid(3))
	p.id = pgid(3)
	p.flags = leafPageFlag
	p.count = 0

	// Write the buffer to our data file.
	if _, err := db.ops.writeAt(buf, 0); err != nil {
		return err
	}
	if err := fdatasync(db); err != nil {
		return err
	}
	return nil
}
```

在init()中:

1. 先分配了4个page大小的buffer；
2. 将第0页和第1页初始化meta页，并指定root bucket的page id为3，存freelist记录的page id为2，当前数据库总页数为4，同时txid分别为0和1。我们将在随后对meta的介绍中说明各个字段的意义；
3. 将第2页初始化为freelist页，即freelist的记录将会存在第2页；
4. 将第3页初始化为一个空页，它可以用来写入K/V记录，请注意它必须是B+ Tree中的叶子节点；
5. 最后，调用写文件函数将buffer中的数据写入文件，同时通过fdatasync()调用将内核中磁盘页缓冲立即写入磁盘。

init()方法创建了一个空的数据库，通过它，我们可以了解boltdb数据库文件的基本格式：数据库文件以页为基本单位，一个数据库文件由若干页组成。一个页的大小是由当前OS决定的，即通过os.GetpageSize()来决定，对于32位系统，它的值一般为4K字节。一个Boltdb数据库文件的前两页是meta页，第三页是记录freelist的页面，事实上，经过若干次读写后，freelist页并不一定会存在第三页，也可能不止一页，我们后面再详细介绍，第4页及后续各页则是用于存储K/V的页面。init()执行完毕后，新创建的数据库文件大小将是16K字节。随后Open()方法便调用db.mmap()方法对该文件进行映射:

```go
//boltdb/bolt/db.go

// mmap opens the underlying memory-mapped file and initializes the meta references.
// minsz is the minimum size that the new mmap can be.
func (db *DB) mmap(minsz int) error {
    db.mmaplock.Lock()
    defer db.mmaplock.Unlock()

    info, err := db.file.Stat()
    if err != nil {
        return fmt.Errorf("mmap stat error: %s", err)
    } else if int(info.Size()) < db.pageSize*2 {
        return fmt.Errorf("file size too small")
    }

    // Ensure the size is at least the minimum size.
    var size = int(info.Size())
    if size < minsz {
        size = minsz
    }
    size, err = db.mmapSize(size)
    if err != nil {
        return err
    }

    // Dereference all mmap references before unmapping.
    if db.rwtx != nil {
        db.rwtx.root.dereference()
    }

    // Unmap existing data before continuing.
    if err := db.munmap(); err != nil {
        return err
    }

    // Memory-map the data file as a byte slice.
    if err := mmap(db, size); err != nil {
        return err
    }

    // Save references to the meta pages.
    db.meta0 = db.page(0).meta()
    db.meta1 = db.page(1).meta()

    // Validate the meta pages. We only return an error if both meta pages fail
    // validation, since meta0 failing validation means that it wasn't saved
    // properly -- but we can recover using meta1. And vice-versa.
    err0 := db.meta0.validate()
    err1 := db.meta1.validate()
    if err0 != nil && err1 != nil {
        return err0
    }

    return nil
}
```

在db.mmap()中:

1. 获取db对象的mmaplock，这里大家可以先忽略它，我们后面再专门介绍DB对象中的锁；
2. 通过db.mmapSize()确定mmap映射文件的长度，因为mmap系统调用时要指定映射文件的起始偏移和长度，即确定映射文件的范围；
3. 通过munmap()将老的内存映射unmap；
4. 通过mmap将文件映射到内存，完成后可以通过db.data来读文件内容了;
5. 读数据库文件的第0页和第1页来初始化db.meta0和db.meta1，前面init()方法中我们了解到db的第0面和第1页确实写入的是meta；
6. 对meta数据进行校验。

db.mmapSize()的实现比较简单，这里不再贴出其代码，它的思想是：映射文件的最小size为32KB，当文件小于1G时，它的大小以加倍的方式增长，当文件大于1G时，每次remmap增加大小时，是以1G为单位增长的。前述init()调用完毕后，文件大小是16KB，即db.mmapSize的传入参数是16384，由于mmapSize()限制最小映射文件大小是32768，故它返回的size值为32768，在随后的mmap()调用中第二个传入参数便是32768，即32K。但此时文件大小才16KB，这个时候映射32KB的文件会不会有问题？window平台和linux平台对此有不同的处理:



由于`boltdb`更新Key-Value操作时，直接通过B-TREE索引直接将数据写到指定的文件page中，因此 仅有一次写入并且不需要log来维护`boltdb`的crash一致性。



# Update的实现过程

刚才讲了Update的操作是会写入到文件中进行持久化的，结合上节中的内容，我们可以很容易的理解其中的流程。

```go
func (db *DB) Update(fn func(*Tx) error) error {
   //生成一个新的Tx对象
   t, err := db.Begin(true)  
   if err != nil {  
      return err  
   }
   //执行匿名函数，如果成功则Commit写入文件，如果不成功则回滚
   err = fn(t) 
   if err != nil {  
      _ = t.Rollback()  
      return err  
   }  
  
   return t.Commit()  
}
```

Begin生成了一个新的Tx对象，并赋予了它一个meta对象，从上文的图中我们知道meta对象中保存了一个默认的bucket（这个默认bucket的page id为3，也就是创建数据库文件时生成的page中的最后一个），所以Tx中的一切都要从这个bucket开始寻找。 假设我们传入的fn的内容为

```go
tx.CreateBucket([]byte("my_bucket"))
```

Tx找到自己的默认bucket，然后在默认bucket中创建新的bucket。

```go
func (b *Bucket) CreateBucket(key []byte) (*Bucket, error) {
   //在该bucket的inodes中寻找这个key
   //inodes中可能没有这个key，因为boltdb并不会把所有的数据读取到inodes中来
   //如果inodes中没有的话就只有去page里面将所有的数据读出来挨个找这个key
   c := b.Cursor()  
   k, _, flags := c.seek(key)  
   
   //如果找到了就说明存在这个key，然么创建失败
   if bytes.Equal(key, k) {  
      if (flags & bucketLeafFlag) != 0 {  
         return nil, ErrBucketExists  
      }  
      return nil, ErrIncompatibleValue  
   }  
  //新创建的bucket都是使用inline类型的page，如果这个bucket下有了子bucket才会为其分配独立的page  
  var bucket = Bucket{  
      bucket:      &bucket{},  
      rootNode:    &node{isLeaf: true},  
      FillPercent: DefaultFillPercent,  
  } 
  //将bucket的内容序列化为[]byte
  var value = bucket.write()  
  
   key = cloneBytes(key)
   //将bucket序列化后的value保存在默认bucket的inodes中
   //由于inodes是切片，所以会按照key来排序插入到对应的位置
   c.node().put(key, key, value, 0, bucketLeafFlag)  
   //将bucket对应的结构体存放在父bucket的buckets切片中
   return b.Bucket(key), nil  
}
```

假如我们在Update的匿名函数中存放了一对key-value：

```go
some_bucket.Put([]byte("mykey"), []byte("myvalue"))
```

Put方法的实现如下：

```go
func (b *Bucket) Put(key []byte, value []byte) error {  
   // 在inodes或者page中寻找这个key
   c := b.Cursor()  
   k, _, flags := c.seek(key)  
  
   //如果找到了就返回一个错误
   if bytes.Equal(key, k) && (flags&bucketLeafFlag) != 0 {  
      return ErrIncompatibleValue  
   }  
  
    
   key = cloneBytes(key)  
   //插入到inodes中
   c.node().put(key, key, value, 0, 0)  
   return nil  
}
```

从CreateBucket和Put两个方法中，读者可以看出两个方法的唯一区别在于CreateBucket会创建一个bucket并序列化为[]byte。所以本质上而言，对父bucket而言，子bucket跟普通数据一样都是[]byte。

从上面的分析可以知道，Update的匿名函数中新生成的数据会被挂在inodes上面，所以在Commit阶段，就会将这些信息写回到文件中存储起来。

```go
func (tx *Tx) Commit() error {  
   //……
   //将inodes中的数据写到page上面
   if err := tx.root.spill(); err != nil {  
      tx.rollback()  
      return err  
   }
   //将目前空闲的所有page的id写入到某个freelist page上面，而meta始终会记录这这个freelist page的id。
   //这样的话，每次读取数据库文件的时候，读取开头的meta信息，就可以知道freelist page的id是多少，然后找到这个page，读取即可知道文件中有哪些空闲的表
   //以后某个时候，如果需要新的page，那么就可以直接使用这些page即可，节省了文件空间。
   tx.db.freelist.free(tx.meta.txid, tx.db.page(tx.meta.freelist))  
   p, err := tx.allocate((tx.db.freelist.size() / tx.db.pageSize) + 1)  
   if err != nil {  
      tx.rollback()  
   return err  
}  
   if err := tx.db.freelist.write(p); err != nil {  
      tx.rollback()  
   return err  
   }  
   tx.meta.freelist = p.id
   //……
   //将所有涉及修改的page同步回文件中。（同步之前在Mmap中）
   if err := tx.write(); err != nil {  
      tx.rollback()  
      return err  
   }  
   //……
     
   tx.close()
  
   return nil  
}
```

至此就分析了一次事务中，数据是如何存储的：从page (mmap)中读取信息 -> 找到bucket -> 对bucket执行读写操作，保存的信息写入到inodes中 -> 事务结束时将inodes中的信息写回到page中(mmap) -> 将mmap中的数据同步回文件中持久化。

回想最开始创建数据库文件的时候，会想这个文件中默认的写入4个page：2个meta page，1个 freelist page， 1个数据page。 2个meta page永远在文件最开始的位置，记录着freelist所在的page，和默认bucket所在的page。通过寻找默认bucket，就可以找到旗下的用户创建的bucket，进而寻找到其他的page 上。 在上文中，我们讲了，如果要在一个bucket中寻找某个key，如果这个bucket的inodes中找不到，那么就会去它所属的page上面找，那么如何在page上找到这个key呢？ 要知道这个，我们应该看inodes上的数据是如何写到page上的，而从page上读数据就是这个操作的反操作。

## 数据page结构

从上文的spill方法开始，这个方法将bucket下所有的inodes信息写到page上。

```go
//spill是一个递归调用，会从下到上先写入子bucket，在写入父bucket
func (b *Bucket) spill() error {  
   // 遍历子bucket
   // 对整个bucket树来说，只有叶节点是inline类型的
   for name, child := range b.buckets {  
   //如果子bucket是inline类型的（参见上文），那么就直接将序列话后的[]byte作为value，key是bucket的名字
   if child.inlineable() {  
      //释放掉原来的inline page
      child.free()  
      //将bucket的数据写入到inline page中
      value = child.write()  
   } else {
	  //如果是普通类型的bucket，就递归先更新子bucket的子bucket
      if err := child.spill(); err != nil {  
         return err  
      }
      //仅将子bucket的头部来作为value
      value = make([]byte, unsafe.Sizeof(bucket{}))  
      var bucket = (*bucket)(unsafe.Pointer(&value[0]))  
      *bucket = *child.bucket  
   }
   var c = b.Cursor()  
   k, _, flags := c.seek([]byte(name))  
   c.node().put([]byte(name), []byte(name), value, 0, bucketLeafFlag)  
   }
```

上面那个递归实现可知，write才是真正写入page的函数

```go
func (b *Bucket) write() []byte {  
   // 分配一块空间 
   var n = b.rootNode  
   var value = make([]byte, bucketHeaderSize+n.size())  
  
   // 写入bucket头部
   var bucket = (*bucket)(unsafe.Pointer(&value[0]))  
   *bucket = *b.bucket  
   
   //通过强制转换，在value的后续空间中写入bucket内的inodes的信息
   var p = (*page)(unsafe.Pointer(&value[bucketHeaderSize]))  
   n.write(p)  
  
   return value  
}
func (n *node) write(p *page) {  
   // Initialize page.  
  if n.isLeaf {  
      p.flags |= leafPageFlag  
  } else {  
      p.flags |= branchPageFlag  
  }  
   //计算需要写入的数目
   p.count = uint16(len(n.inodes))  
  
   // Stop here if there are no items to write.  
   if p.count == 0 {  
      return  
   }  
  
   //b指向需要写入数据的位置
   b := (*[maxAllocSize]byte)(unsafe.Pointer(&p.ptr))[n.pageElementSize()*len(n.inodes):]  
   //遍历所有的inodes
   for i, item := range n.inodes {  
 
      if n.isLeaf {  
         //elem指向写入key-value元数据的位置
         elem := p.leafPageElement(uint16(i))
         //elem所代表的key-value的存储位置距这个elem的相对距离
         elem.pos = uint32(uintptr(unsafe.Pointer(&b[0])) - uintptr(unsafe.Pointer(elem)))  
         elem.flags = item.flags
         //key的字节长度
         elem.ksize = uint32(len(item.key))  
         //value的字节长度
         elem.vsize = uint32(len(item.value))  
      } else {  
         elem := p.branchPageElement(uint16(i))  
         elem.pos = uint32(uintptr(unsafe.Pointer(&b[0])) - uintptr(unsafe.Pointer(elem)))  
         elem.ksize = uint32(len(item.key))  
         elem.pgid = item.pgid
      }
  
      //写入对应的key， value
      copy(b[0:], item.key)  
      b = b[klen:]  
      copy(b[0:], item.value)  
      b = b[vlen:]  
   }  
  
   // DEBUG ONLY: n.dump()  
}
```

可能看了上面的代码，读者还是不太清楚一个数据 page的结构，可以参考下图来理解上文代码。![page 结构](https://ryanyux.github.io/post/go-blotdb-source/datapage.jpg)所以，对于每个page，都会有一个page header，保存了一些page的信息。page.ptr代表着数据的开始位置。如果一个node中有N个inode，那么就会有N个128bit大小的elem，然后再是紧密排列的N对key-value对。





# 